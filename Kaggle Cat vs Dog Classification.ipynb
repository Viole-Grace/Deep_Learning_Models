{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"cats-vs-dogs-cnn-{}\".format(int(time.time()))\n",
    "gpu_limit = tf.GPUOptions(per_process_gpu_memory_fraction=0.4) #40% GPU memory usage\n",
    "sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open('Cat_X.pickle', 'rb'))\n",
    "Y = pickle.load(open('Cat_Y.pickle', 'rb'))\n",
    "\n",
    "from keras.utils import normalize\n",
    "\n",
    "X=normalize(X, axis=1) #normalize image array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers import Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3,3), input_shape = X[0].shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/10\n",
      "19956/19956 [==============================] - 273s 14ms/step - loss: 0.6593 - acc: 0.5992 - val_loss: 0.6312 - val_acc: 0.6641\n",
      "Epoch 2/10\n",
      "19956/19956 [==============================] - 260s 13ms/step - loss: 0.6036 - acc: 0.6780 - val_loss: 0.5804 - val_acc: 0.7072\n",
      "Epoch 3/10\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.5489 - acc: 0.7262 - val_loss: 0.5435 - val_acc: 0.7317\n",
      "Epoch 4/10\n",
      "19956/19956 [==============================] - 258s 13ms/step - loss: 0.5125 - acc: 0.7504 - val_loss: 0.5225 - val_acc: 0.7477\n",
      "Epoch 5/10\n",
      "19956/19956 [==============================] - 253s 13ms/step - loss: 0.4936 - acc: 0.7631 - val_loss: 0.5097 - val_acc: 0.7487\n",
      "Epoch 6/10\n",
      "19956/19956 [==============================] - 255s 13ms/step - loss: 0.4756 - acc: 0.7759 - val_loss: 0.4905 - val_acc: 0.7617\n",
      "Epoch 7/10\n",
      "19956/19956 [==============================] - 251s 13ms/step - loss: 0.4634 - acc: 0.7843 - val_loss: 0.4786 - val_acc: 0.7709\n",
      "Epoch 8/10\n",
      "19956/19956 [==============================] - 252s 13ms/step - loss: 0.4499 - acc: 0.7933 - val_loss: 0.4900 - val_acc: 0.7567\n",
      "Epoch 9/10\n",
      "19956/19956 [==============================] - 252s 13ms/step - loss: 0.4399 - acc: 0.7980 - val_loss: 0.4734 - val_acc: 0.7693\n",
      "Epoch 10/10\n",
      "19956/19956 [==============================] - 253s 13ms/step - loss: 0.4288 - acc: 0.8046 - val_loss: 0.4756 - val_acc: 0.7697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcf87ebbd90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y, validation_split=0.2, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cats-vs-dogs-cnn-{}\".format(int(time.time()))) #save the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat-vs-Dog-1-conv-64-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-64-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-64-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-1-conv-128-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-128-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-128-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-1-conv-256-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-256-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-256-nodes-0-dense-1569796292\n",
      "Cat-vs-Dog-1-conv-64-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-64-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-64-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-1-conv-128-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-128-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-128-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-1-conv-256-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-256-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-256-nodes-1-dense-1569796292\n",
      "Cat-vs-Dog-1-conv-64-nodes-2-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-64-nodes-2-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-64-nodes-2-dense-1569796292\n",
      "Cat-vs-Dog-1-conv-128-nodes-2-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-128-nodes-2-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-128-nodes-2-dense-1569796292\n",
      "Cat-vs-Dog-1-conv-256-nodes-2-dense-1569796292\n",
      "Cat-vs-Dog-2-conv-256-nodes-2-dense-1569796292\n",
      "Cat-vs-Dog-3-conv-256-nodes-2-dense-1569796292\n"
     ]
    }
   ],
   "source": [
    "#tweak models\n",
    "\n",
    "import time\n",
    "\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [64,128,256]\n",
    "conv_layers = [1,2,3]\n",
    "\n",
    "for dense in dense_layers:\n",
    "    for layer in layer_sizes:\n",
    "        for conv in conv_layers:\n",
    "            NAME= \"Cat-vs-Dog-{}-conv-{}-nodes-{}-dense-{}\".format(conv, layer, dense, int(time.time()))\n",
    "            print(NAME) #all layers that we are going to test. Takes a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-64-nodes-0-dense-1569799524\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 48s 2ms/step - loss: 0.6414 - acc: 0.6337 - val_loss: 0.6083 - val_acc: 0.6962\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 48s 2ms/step - loss: 0.5863 - acc: 0.6973 - val_loss: 0.5763 - val_acc: 0.7030\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 49s 2ms/step - loss: 0.5534 - acc: 0.7249 - val_loss: 0.5579 - val_acc: 0.7214\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 49s 2ms/step - loss: 0.5240 - acc: 0.7487 - val_loss: 0.5336 - val_acc: 0.7429\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 49s 2ms/step - loss: 0.5038 - acc: 0.7620 - val_loss: 0.5456 - val_acc: 0.7273\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 49s 2ms/step - loss: 0.4912 - acc: 0.7697 - val_loss: 0.5280 - val_acc: 0.7485\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 50s 2ms/step - loss: 0.4765 - acc: 0.7756 - val_loss: 0.5234 - val_acc: 0.7569\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 50s 2ms/step - loss: 0.4665 - acc: 0.7831 - val_loss: 0.5218 - val_acc: 0.7529\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 50s 3ms/step - loss: 0.4581 - acc: 0.7879 - val_loss: 0.5344 - val_acc: 0.7463\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 50s 2ms/step - loss: 0.4500 - acc: 0.7904 - val_loss: 0.5558 - val_acc: 0.7333\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 50s 2ms/step - loss: 0.4436 - acc: 0.7960 - val_loss: 0.5481 - val_acc: 0.7385\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 50s 2ms/step - loss: 0.4361 - acc: 0.7989 - val_loss: 0.5516 - val_acc: 0.7403\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 46s 2ms/step - loss: 0.4279 - acc: 0.8049 - val_loss: 0.5345 - val_acc: 0.7475\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 43s 2ms/step - loss: 0.4199 - acc: 0.8085 - val_loss: 0.5357 - val_acc: 0.7529\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 43s 2ms/step - loss: 0.4130 - acc: 0.8132 - val_loss: 0.5405 - val_acc: 0.7449\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 43s 2ms/step - loss: 0.4060 - acc: 0.8193 - val_loss: 0.5486 - val_acc: 0.7401\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 43s 2ms/step - loss: 0.3993 - acc: 0.8232 - val_loss: 0.5475 - val_acc: 0.7423\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 43s 2ms/step - loss: 0.3919 - acc: 0.8266 - val_loss: 0.5468 - val_acc: 0.7421\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 43s 2ms/step - loss: 0.3851 - acc: 0.8309 - val_loss: 0.5454 - val_acc: 0.7527\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 43s 2ms/step - loss: 0.3801 - acc: 0.8311 - val_loss: 0.5527 - val_acc: 0.7457\n",
      "2-conv-64-nodes-0-dense-1569800465\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.6525 - acc: 0.6057 - val_loss: 0.6110 - val_acc: 0.6878\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.5875 - acc: 0.6930 - val_loss: 0.5643 - val_acc: 0.7152\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.5422 - acc: 0.7324 - val_loss: 0.5211 - val_acc: 0.7503\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.5102 - acc: 0.7543 - val_loss: 0.5151 - val_acc: 0.7545\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.4957 - acc: 0.7616 - val_loss: 0.5024 - val_acc: 0.7589\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.4834 - acc: 0.7681 - val_loss: 0.4990 - val_acc: 0.7637\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 97s 5ms/step - loss: 0.4716 - acc: 0.7778 - val_loss: 0.4907 - val_acc: 0.7665\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 97s 5ms/step - loss: 0.4635 - acc: 0.7847 - val_loss: 0.4906 - val_acc: 0.7649\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.4522 - acc: 0.7891 - val_loss: 0.4882 - val_acc: 0.7743\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 97s 5ms/step - loss: 0.4442 - acc: 0.7925 - val_loss: 0.4896 - val_acc: 0.7723\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 97s 5ms/step - loss: 0.4367 - acc: 0.7986 - val_loss: 0.4880 - val_acc: 0.7723\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 97s 5ms/step - loss: 0.4320 - acc: 0.7978 - val_loss: 0.4777 - val_acc: 0.7792\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 97s 5ms/step - loss: 0.4202 - acc: 0.8096 - val_loss: 0.4783 - val_acc: 0.7826\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 97s 5ms/step - loss: 0.4131 - acc: 0.8134 - val_loss: 0.4757 - val_acc: 0.7796\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 95s 5ms/step - loss: 0.4045 - acc: 0.8150 - val_loss: 0.4686 - val_acc: 0.7866\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 95s 5ms/step - loss: 0.3976 - acc: 0.8200 - val_loss: 0.5076 - val_acc: 0.7691\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.3915 - acc: 0.8258 - val_loss: 0.4809 - val_acc: 0.7760\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.3794 - acc: 0.8311 - val_loss: 0.4633 - val_acc: 0.7864\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 96s 5ms/step - loss: 0.3744 - acc: 0.8319 - val_loss: 0.4690 - val_acc: 0.7878\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 97s 5ms/step - loss: 0.3672 - acc: 0.8367 - val_loss: 0.4606 - val_acc: 0.7900\n",
      "3-conv-64-nodes-0-dense-1569802391\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.6632 - acc: 0.5958 - val_loss: 0.6514 - val_acc: 0.6194\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 103s 5ms/step - loss: 0.6109 - acc: 0.6690 - val_loss: 0.5824 - val_acc: 0.6910\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.5695 - acc: 0.7078 - val_loss: 0.5521 - val_acc: 0.7126\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 103s 5ms/step - loss: 0.5401 - acc: 0.7281 - val_loss: 0.5296 - val_acc: 0.7369\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 103s 5ms/step - loss: 0.5105 - acc: 0.7492 - val_loss: 0.5109 - val_acc: 0.7513\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.4880 - acc: 0.7658 - val_loss: 0.5252 - val_acc: 0.7485\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 103s 5ms/step - loss: 0.4670 - acc: 0.7795 - val_loss: 0.5106 - val_acc: 0.7599\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 103s 5ms/step - loss: 0.4485 - acc: 0.7924 - val_loss: 0.4687 - val_acc: 0.7812\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.4292 - acc: 0.8008 - val_loss: 0.4623 - val_acc: 0.7876\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.4097 - acc: 0.8134 - val_loss: 0.4716 - val_acc: 0.7886\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.3949 - acc: 0.8214 - val_loss: 0.4750 - val_acc: 0.7774\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.3787 - acc: 0.8303 - val_loss: 0.4615 - val_acc: 0.7886\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.3650 - acc: 0.8402 - val_loss: 0.4548 - val_acc: 0.7934\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.3521 - acc: 0.8433 - val_loss: 0.4458 - val_acc: 0.7962\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.3353 - acc: 0.8512 - val_loss: 0.4521 - val_acc: 0.7956\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.3231 - acc: 0.8585 - val_loss: 0.4537 - val_acc: 0.7992\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.3123 - acc: 0.8635 - val_loss: 0.4605 - val_acc: 0.8024\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 103s 5ms/step - loss: 0.2960 - acc: 0.8708 - val_loss: 0.4860 - val_acc: 0.7916\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 103s 5ms/step - loss: 0.2831 - acc: 0.8794 - val_loss: 0.4735 - val_acc: 0.7918\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 104s 5ms/step - loss: 0.2728 - acc: 0.8841 - val_loss: 0.4687 - val_acc: 0.8032\n",
      "1-conv-128-nodes-0-dense-1569804464\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.6436 - acc: 0.6275 - val_loss: 0.6064 - val_acc: 0.6800\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 73s 4ms/step - loss: 0.5843 - acc: 0.6974 - val_loss: 0.5842 - val_acc: 0.6958\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 73s 4ms/step - loss: 0.5411 - acc: 0.7368 - val_loss: 0.5479 - val_acc: 0.7301\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.5102 - acc: 0.7558 - val_loss: 0.5358 - val_acc: 0.7403\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.4892 - acc: 0.7678 - val_loss: 0.5314 - val_acc: 0.7467\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.4755 - acc: 0.7788 - val_loss: 0.5379 - val_acc: 0.7389\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 73s 4ms/step - loss: 0.4639 - acc: 0.7840 - val_loss: 0.5337 - val_acc: 0.7439\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.4507 - acc: 0.7921 - val_loss: 0.5433 - val_acc: 0.7397\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.4358 - acc: 0.7992 - val_loss: 0.5563 - val_acc: 0.7297\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.4241 - acc: 0.8075 - val_loss: 0.5335 - val_acc: 0.7459\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.4099 - acc: 0.8159 - val_loss: 0.5368 - val_acc: 0.7487\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3979 - acc: 0.8205 - val_loss: 0.5352 - val_acc: 0.7525\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3846 - acc: 0.8294 - val_loss: 0.5448 - val_acc: 0.7487\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3734 - acc: 0.8365 - val_loss: 0.5505 - val_acc: 0.7429\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3598 - acc: 0.8438 - val_loss: 0.5622 - val_acc: 0.7423\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3493 - acc: 0.8494 - val_loss: 0.5639 - val_acc: 0.7453\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3384 - acc: 0.8564 - val_loss: 0.5646 - val_acc: 0.7471\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3287 - acc: 0.8616 - val_loss: 0.5706 - val_acc: 0.7449\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3161 - acc: 0.8689 - val_loss: 0.5900 - val_acc: 0.7367\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 74s 4ms/step - loss: 0.3085 - acc: 0.8746 - val_loss: 0.5784 - val_acc: 0.7431\n",
      "2-conv-128-nodes-0-dense-1569805939\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.6423 - acc: 0.6267 - val_loss: 0.6374 - val_acc: 0.6299\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 243s 12ms/step - loss: 0.5596 - acc: 0.7120 - val_loss: 0.5258 - val_acc: 0.7393\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 243s 12ms/step - loss: 0.5131 - acc: 0.7513 - val_loss: 0.5861 - val_acc: 0.6996\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.4844 - acc: 0.7703 - val_loss: 0.4945 - val_acc: 0.7681\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 243s 12ms/step - loss: 0.4619 - acc: 0.7865 - val_loss: 0.4790 - val_acc: 0.7778\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.4458 - acc: 0.7937 - val_loss: 0.4885 - val_acc: 0.7709\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.4304 - acc: 0.8026 - val_loss: 0.4645 - val_acc: 0.7854\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.4104 - acc: 0.8154 - val_loss: 0.4525 - val_acc: 0.7974\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.3913 - acc: 0.8242 - val_loss: 0.4701 - val_acc: 0.7828\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.3776 - acc: 0.8313 - val_loss: 0.4632 - val_acc: 0.7904\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 241s 12ms/step - loss: 0.3630 - acc: 0.8354 - val_loss: 0.4571 - val_acc: 0.7934\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.3437 - acc: 0.8498 - val_loss: 0.4866 - val_acc: 0.7840\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 242s 12ms/step - loss: 0.3293 - acc: 0.8578 - val_loss: 0.4548 - val_acc: 0.8026\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 246s 12ms/step - loss: 0.3129 - acc: 0.8628 - val_loss: 0.4552 - val_acc: 0.8038\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 257s 13ms/step - loss: 0.2965 - acc: 0.8730 - val_loss: 0.4535 - val_acc: 0.8022\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 257s 13ms/step - loss: 0.2827 - acc: 0.8778 - val_loss: 0.4860 - val_acc: 0.7922\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 248s 12ms/step - loss: 0.2682 - acc: 0.8876 - val_loss: 0.5158 - val_acc: 0.7864\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 243s 12ms/step - loss: 0.2511 - acc: 0.8932 - val_loss: 0.4895 - val_acc: 0.7964\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 243s 12ms/step - loss: 0.2366 - acc: 0.9037 - val_loss: 0.5286 - val_acc: 0.7820\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 243s 12ms/step - loss: 0.2225 - acc: 0.9110 - val_loss: 0.5632 - val_acc: 0.7834\n",
      "3-conv-128-nodes-0-dense-1569810825\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 271s 14ms/step - loss: 0.6633 - acc: 0.5927 - val_loss: 0.6265 - val_acc: 0.6559\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 269s 13ms/step - loss: 0.5957 - acc: 0.6866 - val_loss: 0.6204 - val_acc: 0.6657\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 269s 13ms/step - loss: 0.5341 - acc: 0.7359 - val_loss: 0.5141 - val_acc: 0.7483\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 269s 13ms/step - loss: 0.4891 - acc: 0.7677 - val_loss: 0.4944 - val_acc: 0.7579\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 269s 13ms/step - loss: 0.4656 - acc: 0.7802 - val_loss: 0.4717 - val_acc: 0.7780\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.4413 - acc: 0.7950 - val_loss: 0.4681 - val_acc: 0.7864\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 269s 13ms/step - loss: 0.4183 - acc: 0.8062 - val_loss: 0.4453 - val_acc: 0.7984\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.3962 - acc: 0.8204 - val_loss: 0.4346 - val_acc: 0.8032\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.3780 - acc: 0.8315 - val_loss: 0.4314 - val_acc: 0.8034\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.3566 - acc: 0.8438 - val_loss: 0.4308 - val_acc: 0.8048\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.3374 - acc: 0.8499 - val_loss: 0.4294 - val_acc: 0.8046\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.3170 - acc: 0.8630 - val_loss: 0.4334 - val_acc: 0.8098\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.2967 - acc: 0.8707 - val_loss: 0.4359 - val_acc: 0.8024\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.2791 - acc: 0.8807 - val_loss: 0.4529 - val_acc: 0.8100\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 270s 14ms/step - loss: 0.2587 - acc: 0.8912 - val_loss: 0.4565 - val_acc: 0.8096\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 269s 13ms/step - loss: 0.2426 - acc: 0.8981 - val_loss: 0.4719 - val_acc: 0.8066\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 269s 13ms/step - loss: 0.2201 - acc: 0.9125 - val_loss: 0.4836 - val_acc: 0.8102\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 269s 13ms/step - loss: 0.2011 - acc: 0.9200 - val_loss: 0.5061 - val_acc: 0.8066\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 269s 14ms/step - loss: 0.1903 - acc: 0.9237 - val_loss: 0.5777 - val_acc: 0.7950\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 268s 13ms/step - loss: 0.1716 - acc: 0.9325 - val_loss: 0.5247 - val_acc: 0.8010\n",
      "1-conv-256-nodes-0-dense-1569816215\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 147s 7ms/step - loss: 0.6447 - acc: 0.6254 - val_loss: 0.6125 - val_acc: 0.6880\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 147s 7ms/step - loss: 0.5857 - acc: 0.6993 - val_loss: 0.5757 - val_acc: 0.7166\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 147s 7ms/step - loss: 0.5469 - acc: 0.7282 - val_loss: 0.5494 - val_acc: 0.7325\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 147s 7ms/step - loss: 0.5187 - acc: 0.7515 - val_loss: 0.5446 - val_acc: 0.7333\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 147s 7ms/step - loss: 0.4970 - acc: 0.7624 - val_loss: 0.5546 - val_acc: 0.7216\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 149s 7ms/step - loss: 0.4763 - acc: 0.7741 - val_loss: 0.5375 - val_acc: 0.7403\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 143s 7ms/step - loss: 0.4556 - acc: 0.7881 - val_loss: 0.5329 - val_acc: 0.7473\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 144s 7ms/step - loss: 0.4390 - acc: 0.7977 - val_loss: 0.5354 - val_acc: 0.7435\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 144s 7ms/step - loss: 0.4210 - acc: 0.8064 - val_loss: 0.5340 - val_acc: 0.7473\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 159s 8ms/step - loss: 0.4049 - acc: 0.8173 - val_loss: 0.5463 - val_acc: 0.7417\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 159s 8ms/step - loss: 0.3851 - acc: 0.8301 - val_loss: 0.5508 - val_acc: 0.7419\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 160s 8ms/step - loss: 0.3692 - acc: 0.8408 - val_loss: 0.5658 - val_acc: 0.7381\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 160s 8ms/step - loss: 0.3508 - acc: 0.8473 - val_loss: 0.5725 - val_acc: 0.7409\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 147s 7ms/step - loss: 0.3392 - acc: 0.8524 - val_loss: 0.5678 - val_acc: 0.7399\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 147s 7ms/step - loss: 0.3225 - acc: 0.8640 - val_loss: 0.5678 - val_acc: 0.7417\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 148s 7ms/step - loss: 0.3056 - acc: 0.8760 - val_loss: 0.5959 - val_acc: 0.7313\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 148s 7ms/step - loss: 0.2955 - acc: 0.8782 - val_loss: 0.6081 - val_acc: 0.7363\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 148s 7ms/step - loss: 0.2786 - acc: 0.8875 - val_loss: 0.6152 - val_acc: 0.7295\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 148s 7ms/step - loss: 0.2662 - acc: 0.8959 - val_loss: 0.6137 - val_acc: 0.7375\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 148s 7ms/step - loss: 0.2523 - acc: 0.9010 - val_loss: 0.6323 - val_acc: 0.7285\n",
      "2-conv-256-nodes-0-dense-1569819199\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 751s 38ms/step - loss: 0.6501 - acc: 0.6185 - val_loss: 0.6086 - val_acc: 0.6687\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 751s 38ms/step - loss: 0.5822 - acc: 0.6986 - val_loss: 0.5397 - val_acc: 0.7345\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 751s 38ms/step - loss: 0.5230 - acc: 0.7468 - val_loss: 0.5189 - val_acc: 0.7547\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 751s 38ms/step - loss: 0.4981 - acc: 0.7623 - val_loss: 0.5006 - val_acc: 0.7671\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 750s 38ms/step - loss: 0.4767 - acc: 0.7742 - val_loss: 0.5003 - val_acc: 0.7621\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 752s 38ms/step - loss: 0.4622 - acc: 0.7813 - val_loss: 0.4850 - val_acc: 0.7792\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 751s 38ms/step - loss: 0.4462 - acc: 0.7922 - val_loss: 0.4735 - val_acc: 0.7788\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 752s 38ms/step - loss: 0.4280 - acc: 0.8030 - val_loss: 0.4817 - val_acc: 0.7707\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 751s 38ms/step - loss: 0.4132 - acc: 0.8127 - val_loss: 0.4881 - val_acc: 0.7754\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 753s 38ms/step - loss: 0.3960 - acc: 0.8208 - val_loss: 0.4737 - val_acc: 0.7824\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 753s 38ms/step - loss: 0.3807 - acc: 0.8295 - val_loss: 0.4627 - val_acc: 0.7862\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 753s 38ms/step - loss: 0.3636 - acc: 0.8408 - val_loss: 0.4705 - val_acc: 0.7834\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 752s 38ms/step - loss: 0.3528 - acc: 0.8449 - val_loss: 0.4764 - val_acc: 0.7908\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 753s 38ms/step - loss: 0.3305 - acc: 0.8590 - val_loss: 0.4837 - val_acc: 0.7828\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 753s 38ms/step - loss: 0.3196 - acc: 0.8607 - val_loss: 0.5189 - val_acc: 0.7800\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 754s 38ms/step - loss: 0.3029 - acc: 0.8707 - val_loss: 0.4965 - val_acc: 0.7733\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 752s 38ms/step - loss: 0.2914 - acc: 0.8746 - val_loss: 0.4941 - val_acc: 0.7818\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 753s 38ms/step - loss: 0.2805 - acc: 0.8805 - val_loss: 0.4879 - val_acc: 0.7938\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 753s 38ms/step - loss: 0.2624 - acc: 0.8898 - val_loss: 0.5100 - val_acc: 0.7914\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 755s 38ms/step - loss: 0.2486 - acc: 0.8976 - val_loss: 0.5490 - val_acc: 0.7731\n",
      "3-conv-256-nodes-0-dense-1569834243\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 870s 44ms/step - loss: 0.6648 - acc: 0.5978 - val_loss: 0.6148 - val_acc: 0.6822\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 868s 44ms/step - loss: 0.5763 - acc: 0.6994 - val_loss: 0.5519 - val_acc: 0.7277\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 868s 43ms/step - loss: 0.5090 - acc: 0.7532 - val_loss: 0.4897 - val_acc: 0.7643\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 867s 43ms/step - loss: 0.4661 - acc: 0.7786 - val_loss: 0.4716 - val_acc: 0.7812\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 868s 43ms/step - loss: 0.4351 - acc: 0.7981 - val_loss: 0.5588 - val_acc: 0.7220\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 866s 43ms/step - loss: 0.3964 - acc: 0.8209 - val_loss: 0.4507 - val_acc: 0.7924\n",
      "Epoch 7/20\n",
      " 9632/19956 [=============>................] - ETA: 7:56 - loss: 0.3533 - acc: 0.8427"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f4230254f942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m#             val_loss, val_acc =  model.evaluate(X,Y,validation_split=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#             NAME=\"accuracy_{}-\".format(val_acc)+NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/viole/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/viole/.local/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/viole/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/viole/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dense in dense_layers:\n",
    "    for layer in layer_sizes:\n",
    "        for conv in conv_layers:\n",
    "            NAME= \"{}-conv-{}-nodes-{}-dense-{}\".format(conv, layer, dense, int(time.time()))\n",
    "            print(NAME)\n",
    "            \n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer, (3,3), input_shape = X[0].shape))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "            \n",
    "            for c in range(conv-1):\n",
    "                \n",
    "                model.add(Conv2D(layer, (3,3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for d in range(dense):\n",
    "                model.add(Dense(layer))\n",
    "                model.add(Activationtivation('relu'))\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "            model.fit(X,Y, validation_split = 0.2, epochs = 20, batch_size = 32)\n",
    "#             val_loss, val_acc =  model.evaluate(X,Y,validation_split=0.2)\n",
    "#             NAME=\"accuracy_{}-\".format(val_acc)+NAME\n",
    "            model.save(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
